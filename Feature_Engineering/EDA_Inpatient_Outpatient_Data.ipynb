{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d7867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/Users/bernardoloureiro/template-lib')\n",
    "\n",
    "from utils.notebookhelpers.helpers import Helpers\n",
    "from utils.dtos.templateOutputCollection import TemplateOutputCollection\n",
    "from utils.dtos.variable import Metadata\n",
    "from utils.dtos.templateOutput import TemplateOutput\n",
    "from utils.dtos.templateOutput import OutputType\n",
    "from utils.dtos.templateOutput import ChartType\n",
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dateutil import parser\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "import math\n",
    "import scipy as scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28efa2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Context is not present for given context_id: EDA_Inpatient_Outpatient_Data. Make sure you declare context_id at the top of the cell and run prepareForLocal in your flow file before testing transform file.\n",
      "WARNING:Context is not present for given context_id: EDA_Inpatient_Outpatient_Data. Make sure you declare context_id at the top of the cell and run prepareForLocal in your flow file before testing transform file.\n",
      "WARNING:Context is not present for given context_id: EDA_Inpatient_Outpatient_Data. Make sure you declare context_id at the top of the cell and run prepareForLocal in your flow file before testing transform file.\n",
      "WARNING:Context is not present for given context_id: EDA_Inpatient_Outpatient_Data. Make sure you declare context_id at the top of the cell and run prepareForLocal in your flow file before testing transform file.\n",
      "WARNING:Context is not present for given context_id: EDA_Inpatient_Outpatient_Data. Make sure you declare context_id at the top of the cell and run prepareForLocal in your flow file before testing transform file.\n"
     ]
    }
   ],
   "source": [
    "inputDatasetParameter=Helpers.get_or_create_input_dataset(\n",
    "    name=\"inputBeneDataset3\",\n",
    "    metadata=Metadata(input_name='inpatient data', is_required=True, tooltip='inpatient  Dataset for EDA'),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "inputDatasetParameter2=Helpers.get_or_create_input_dataset(\n",
    "    name=\"inputBeneDataset4\",\n",
    "    metadata=Metadata(input_name='outpatient data', is_required=True, tooltip=' outpatient Dataset for EDA'),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "inputDatasetParameter3=Helpers.get_or_create_input_dataset(\n",
    "    name=\"inputBeneDataset5\",\n",
    "    metadata=Metadata(input_name='target label data', is_required=True, tooltip=' Label Dataset'),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "inputDatasetParameter4=Helpers.get_or_create_input_dataset(\n",
    "    name=\"inputBeneDataset6\",\n",
    "    metadata=Metadata(input_name='train_bene_df', is_required=True, tooltip='Benefeciary Dataset'),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "# Gender = Helpers.get_or_create_input_var(\n",
    "#     name=\"Gender\",\n",
    "#     metadata=Metadata(input_name=\"Longitude\", is_required=True, tooltip=\"Longitude\", multiple=False, datatypes=[\"DOUBLE\", \"LONG\"], options=['FIELDS', 'CONSTANT'], datasets=['GeoDataset']),\n",
    "#     local_context=locals()\n",
    "# )\n",
    "\n",
    "EDA_Inpatient_Outpatient=Helpers.get_or_create_output_chart(\n",
    " name=\"EDA_Inpatient_Outpatient_Data\",\n",
    "    metadata=Metadata(input_name='EDA_Inpatient_Outpatient_Data', is_required=True, tooltip='Name of the chart to be created'),\n",
    "    local_context=locals()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "430af644",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextId = \"EDA_Inpatient_Outpatient_Data\"\n",
    "context = Helpers.getOrCreateContext(contextId = contextId, localVars=locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e725fb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'entityPaths'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m entities\u001b[38;5;241m=\u001b[39m\u001b[43mHelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetAllEntities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m IpDataset \u001b[38;5;241m=\u001b[39m inputDatasetParameter\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m      3\u001b[0m OpDataset \u001b[38;5;241m=\u001b[39m inputDatasetParameter2\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\utils\\notebookhelpers\\helpers.py:213\u001b[0m, in \u001b[0;36mHelpers.getAllEntities\u001b[1;34m(context)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03mReturns all the entity names in the context\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m:param context:\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m:return: list of all entity names\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m entities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 213\u001b[0m entityPaths \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentityPaths\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entityPath \u001b[38;5;129;01min\u001b[39;00m entityPaths:\n\u001b[0;32m    215\u001b[0m     entities\u001b[38;5;241m.\u001b[39mappend(entityPath[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'entityPaths'"
     ]
    }
   ],
   "source": [
    "entities=Helpers.getAllEntities(context)\n",
    "IpDataset = inputDatasetParameter.value\n",
    "OpDataset = inputDatasetParameter2.value\n",
    "train_bene_df=inputDatasetParameter4.value\n",
    "train_tgt_Dataset = inputDatasetParameter3.value\n",
    "\n",
    "\n",
    "EDA_Inpatient_Outpatient=EDA_Inpatient_Outpatient.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1768ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Helpers.getEntityData(context,IpDataset)\n",
    "df2 = Helpers.getEntityData(context,OpDataset)\n",
    "df4 = Helpers.getEntityData(context,train_bene_df)\n",
    "df3 = Helpers.getEntityData(context,train_tgt_Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c52417",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip_df = df.copy()\n",
    "train_op_df = df2.copy()\n",
    "train_tgt_lbls_df = df3.copy()\n",
    "train_bene_df = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f6eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',30)\n",
    "label_font_dict = {'family':'sans-serif','size':13.5,'color':'brown','style':'italic'}\n",
    "title_font_dict = {'family':'sans-serif','size':16.5,'color':'Blue','style':'italic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad6e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b4552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7be5ad8",
   "metadata": {},
   "source": [
    "# EDA Start`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op_df[\"Admitted?\"] = 0\n",
    "train_op_df['ClaimStartDt'] = pd.to_datetime(train_op_df['ClaimStartDt'], format=\"%Y-%m-%d\")\n",
    "train_op_df['ClaimEndDt'] = pd.to_datetime(train_op_df['ClaimEndDt'], format=\"%Y-%m-%d\")\n",
    "train_op_df['Claim_Duration'] = (train_op_df['ClaimEndDt'] - train_op_df['ClaimStartDt']).dt.days\n",
    "ccc = train_op_df['Claim_Duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I'm displaying the number of only in-patients and out-patients\n",
    "with plt.style.context('seaborn-poster'):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ccc.plot(kind='hist', colormap=\"viridis\");\n",
    "    # Providing the labels and title to the graph\n",
    "    plt.xlabel(\"Claim Duration(in days)\", fontdict=label_font_dict)\n",
    "    plt.minorticks_on()\n",
    "    plt.title(\"Distribution of Claim Duration Days\\n\", fontdict=title_font_dict)\n",
    "    plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74087c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgChart = Helpers.createTemplateOutputPlotlibChart(context, chartTitle='Distribution of Claim Duration Days\\n',\n",
    "                                                    plt=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9889b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aec7e25",
   "metadata": {},
   "source": [
    "# EDA On all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f563875",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-poster'):\n",
    "    fig = train_tgt_lbls_df[\"PotentialFraud\"].value_counts().plot(kind='bar', color=['green','orange'])\n",
    "    # Using the \"patches\" function we will get the location of the rectangle bars from the graph.\n",
    "    ## Then by using those location(width & height) values we will add the annotations\n",
    "    for p in fig.patches:\n",
    "        width = p.get_width()\n",
    "        height = p.get_height()\n",
    "        x, y = p.get_xy()\n",
    "        fig.annotate(f'{str(round((height*100)/train_tgt_lbls_df.shape[0],2))+\"%\"}', (x + width/2, y + height*1.015), ha='center', fontsize=13.5)\n",
    "    # Providing the labels and title to the graph\n",
    "    plt.xlabel(\"Provider Fraud or Not?\", fontdict=label_font_dict)\n",
    "    plt.ylabel(\"Number or % share of providers\\n\", fontdict=label_font_dict)\n",
    "    plt.yticks(np.arange(0,5100,500))\n",
    "    plt.grid(which='major', linestyle=\"--\", color='lightgrey')\n",
    "    plt.minorticks_on()\n",
    "    plt.title(\"Distribution of Fraud & Non-fraud providers\\n\", fontdict=title_font_dict)\n",
    "    plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0220ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgChart2 = Helpers.createTemplateOutputPlotlibChart(context, chartTitle='Distribution of Fraud & Non-fraud providers\\n',\n",
    "                                                    plt=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip_df[\"Admitted?\"] = 1\n",
    "common_cols = [col for col in train_ip_df.columns if col in train_op_df.columns]\n",
    "train_ip_df['ClaimStartDt'] = pd.to_datetime(train_ip_df['ClaimStartDt'], format=\"%Y-%m-%d\")\n",
    "train_ip_df['ClaimEndDt'] = pd.to_datetime(train_ip_df['ClaimEndDt'], format=\"%Y-%m-%d\")\n",
    "train_op_df['ClaimStartDt'] = pd.to_datetime(train_op_df['ClaimStartDt'], format=\"%Y-%m-%d\")\n",
    "train_op_df['ClaimEndDt'] = pd.to_datetime(train_op_df['ClaimEndDt'], format=\"%Y-%m-%d\")\n",
    "train_ip_op_df = pd.merge(left=train_ip_df, right=train_op_df, left_on=common_cols, right_on=common_cols, how=\"outer\")\n",
    "train_ip_op_bene_df = pd.merge(left=train_ip_op_df, right=train_bene_df, left_on='BeneID', right_on='BeneID',how='inner')\n",
    "train_iobp_df = pd.merge(left=train_ip_op_bene_df, right=train_tgt_lbls_df, left_on='Provider', right_on='Provider',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb1730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prvs_claims_df = pd.DataFrame(train_iobp_df.groupby(['Provider'])['ClaimID'].count()).reset_index()\n",
    "prvs_claims_tgt_lbls_df = pd.merge(left=prvs_claims_df, right=train_tgt_lbls_df, on='Provider', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(train_iobp_df['PotentialFraud'].value_counts()), \"\\n\")\n",
    "\n",
    "with plt.style.context('seaborn-poster'):\n",
    "    fig = train_iobp_df['PotentialFraud'].value_counts().plot(kind='bar', color=['green','orange'])\n",
    "    # Using the \"patches\" function we will get the location of the rectangle bars from the graph.\n",
    "    ## Then by using those location(width & height) values we will add the annotations\n",
    "    for p in fig.patches:\n",
    "        width = p.get_width()\n",
    "        height = p.get_height()\n",
    "        x, y = p.get_xy()\n",
    "        fig.annotate(f'{str(round((height*100)/train_iobp_df.shape[0],2))+\"%\"}', (x + width/2, y + height*1.015), ha='center', fontsize=13.5)\n",
    "    # Providing the labels and title to the graph\n",
    "    plt.xlabel(\"Fraud or Not?\", fontdict=label_font_dict)\n",
    "    plt.ylabel(\"Number (or %) of claims\\n\", fontdict=label_font_dict)\n",
    "    plt.grid(which='major', linestyle=\"--\", color='lightgrey')\n",
    "    plt.minorticks_on()\n",
    "    plt.title(\"Distribution of Fraud & Non-fraud claims\\n\", fontdict=title_font_dict)\n",
    "    plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f50487",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgChart3 = Helpers.createTemplateOutputPlotlibChart(context, chartTitle='Distribution of Fraud & Non-fraud claims\\n',\n",
    "                                                    plt=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1975e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['DOB'] = pd.to_datetime(train_iobp_df['DOB'], format=\"%Y-%m-%d\")\n",
    "train_iobp_df['DOD'] = pd.to_datetime(train_iobp_df['DOD'], format=\"%Y-%m-%d\")\n",
    "train_iobp_df['Is_Alive?'] = train_iobp_df['DOD'].apply(lambda val: 'No' if val != val else 'Yes')\n",
    "train_iobp_df['ClaimStartDt'] = pd.to_datetime(train_iobp_df['ClaimStartDt'], format=\"%Y-%m-%d\")\n",
    "train_iobp_df['ClaimEndDt'] = pd.to_datetime(train_iobp_df['ClaimEndDt'], format=\"%Y-%m-%d\")\n",
    "\n",
    "train_iobp_df['Claim_Duration'] = (train_iobp_df['ClaimEndDt'] - train_iobp_df['ClaimStartDt']).dt.days\n",
    "# tmp = train_iobp_df['Claim_Duration'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn'):\n",
    "    fig = sns.boxenplot(data=train_iobp_df, x='PotentialFraud',y='Claim_Duration', palette='dark')\n",
    "    # Providing the labels and title to the graph\n",
    "    plt.xlabel(\"Potentially Fraud?\", fontdict=label_font_dict)\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.ylabel(\"Claim Duration (in days)\\n\", fontdict=label_font_dict)\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(which='major', linestyle=\"--\", color='lightgrey')\n",
    "    plt.title(\"Claim Duration for Potentially Fraud & Non-Fraud Providers\\n\", fontdict=title_font_dict)\n",
    "    plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgChart4 = Helpers.createTemplateOutputPlotlibChart(context, chartTitle='Claim Duration for Potentially Fraud & Non-Fraud Providers\\n',\n",
    "                                                    plt=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77deeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                     \n",
    "\n",
    "\n",
    "outputCollection = Helpers.createOutputCollection(context)\n",
    "\n",
    "\n",
    "outputCollection.addTemplateOutput(imgChart)\n",
    "outputCollection.addTemplateOutput(imgChart2)\n",
    "outputCollection.addTemplateOutput(imgChart3)\n",
    "outputCollection.addTemplateOutput(imgChart4)\n",
    "# outputCollection.addTemplateOutput(imgChart5)\n",
    "# outputCollection.addTemplateOutput(imgChart6)\n",
    "# outputCollection.addTemplateOutput(imgChart7)\n",
    "# outputCollection.addTemplateOutput(imgChart8)\n",
    "# outputCollection.addTemplateOutput(imgChart9)\n",
    "# outputCollection.addTemplateOutput(imgChart10)\n",
    "\n",
    "# outputCollection.addTemplateOutput(imgChart11)\n",
    "# outputCollection.addTemplateOutput(imgChart12)\n",
    "# outputCollection.addTemplateOutput(imgChart13)\n",
    "# outputCollection.addTemplateOutput(imgChart14)\n",
    "# # outputCollection.addTemplateOutput(imgChart15)\n",
    "# outputCollection.addTemplateOutput(imgChart16)\n",
    "# outputCollection.addTemplateOutput(imgChart17)\n",
    "# outputCollection.addTemplateOutput(imgChart18)\n",
    "# outputCollection.addTemplateOutput(imgChart19)\n",
    "# outputCollection.addTemplateOutput(imgChart20)\n",
    "# outputCollection.addTemplateOutput(imgChart21)\n",
    "\n",
    "\n",
    "\n",
    "Helpers.save(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b08d5",
   "metadata": {},
   "source": [
    "Helpers.save(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
