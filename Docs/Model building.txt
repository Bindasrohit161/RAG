Model building
=======================

This example file will walk you through the steps involved to build an
ML model using historic data and predict on new incoming data.

The example provides historic sensor data of windturbines and their
failures. A model will be built based on this historic data. New daily
sensor data will be passed through the model to predict failures.

Download the project files here:`Reference
Project <sample_projects/buildandpredict.zip>`__

Building an ML model and predicting on RapidCanvas involves the
following steps:

-  Import functions
-  Authenticate your client
-  Create a custom environment
-  Create a new project

-  Create a build pipeline

   -  Add Input Datasets
   -  Transform your raw data

   -  Create recipe for feature engineering
   -  Create recipe to Aggregate raw data
   -  Build ML model

      -  Add the dataset
      -  Create a recipe to build a random forest, ada boost and lighgbm model 

-  Exploratory Data Analysis
   -  Beneficiary Data EDA
   -  Entire Data EDA


Import function
---------------

.. code:: ipython3

    from utils.rc.client.requests import Requests
    from utils.rc.client.auth import AuthClient

    from utils.rc.dtos.project import Project
    from utils.rc.dtos.dataset import Dataset
    from utils.rc.dtos.recipe import Recipe
    from utils.rc.dtos.transform import Transform
    from utils.rc.dtos.template import Template, TemplateTransform, TemplateInput
    from utils.rc.dtos.template_v2 import TemplateV2, TemplateTransformV2
    from utils.rc.dtos.env import Env
    from utils.rc.dtos.env import EnvType
    import json
    import pandas as pd
    import logging
    logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)

Authenticate your client
------------------------

.. code:: ipython3

    #Requests.setRootHost("https://staging.dev.rapidcanvas.net/api/") #uncomment this line during your run
    AuthClient.setToken() #you can find your token in RapidCanvas UI under tools/token

Create a custom environment
---------------------------

Here are the available custom environments and their usage gudelines

| SMALL: 1 Core, 2GB Memmory
| MEDIUM: 2 Cores, 4GB Memmory
| LARGE: 4 Cores, 8GB Memmory
| CPU_LARGE: 8 Cores, 16GB Memmory
| MAX_LARGE: 12 Cores, 32GB Memmory
| EXTRA_MAX_LARGE: 12 Cores, 48GB Memmory

.. code:: ipython3

    ## Environment Creation
    Healthcare_Fraud_env = Env.createEnv(
        name="Healthcare_Fraud_detection",
        description="env for my HealthCare provider Fraud detection project",
        envType=EnvType.LARGE, #pick one of the pre-defined configs
        requirements="imblearn matplotlib seaborn scipy scikit-learn==0.23.2 pycaret markupsafe==2.0.1 Jinja2" #additional packages to be installed for your custom env
    )

Create a Project
----------------

Create a new project under your tenant

.. code:: ipython3

    project = Project.create(
        name='Healthcare_Fraud_detection',
        description='HealthCare provider Fraud detection',
        createEmpty=True,
        envId=Healthcare_Fraud_env.id,
    #     envId='Healthcare_Fraud_detection2'
    )
    project.id

**This has now created a new project named â€œBuild and Predictâ€ under
your tenant. You can check the same on the RapidCanvas UI by logging in
here:** `RapidCanvas UI <https://staging.dev.rapidcanvas.net/>`__

Getting Templates
~~~~~~~~~~~~~~~~~

You can utilize pre-built RapidCanvas templates as part of your project.
In this section we are defining some prebuilt templates which will be
used during the build pipeline.

.. code:: ipython3

    # This gets all available templates
    templates = TemplateV2.get_all()

.. code:: ipython3

    # Relevant templates for this project are being fetched
    feature_engineering_template = TemplateV2.get_template_by('feature_engineering')
    data_aggregation_template = TemplateV2.get_template_by('Data_aggregation')
    Classification_template = TemplateV2.get_template_by('ML Classification')


Create a build pipeline
-----------------------

As part of the section, we will follow all the relevant steps to build
an ML model using historic data.

Add Input Datasets - Build pipeline
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

As part of the build pipeline, we are adding 4 data sets to the project,
Beneficiary data, Inpatient data, Outpatient data and Train(Label) data. 
Beneficiary data contains beneficiary KYC details like health conditions,region they belong to etc.
Inpatient data provides insights about the claims filed for those patients which are admitted in the hospitals.It also provides additional details like their admission and discharge dates and admit diagnosis code.
Outpatient data provides details about the claims filed for those patients who visits hospitals and not admitted in it.
Train data contains traget lebel of provider fraud binary class.

.. code:: ipython3

    Beneficiarydata = project.addDataset(
        dataset_name='Train_Beneficiarydata-1542865627584',
        dataset_description='Train Bene',
        dataset_file_path='data/Train_Beneficiarydata-1542865627584.csv'
    )

    Inpatientdata = project.addDataset(
        dataset_name='Train_Inpatientdata-1542865627584',
        dataset_description='Train_IP',
        dataset_file_path='data/Train_Inpatientdata-1542865627584.csv'
    )

    Outpatientdata = project.addDataset(
        dataset_name='Train_Outpatientdata-1542865627584',
        dataset_description='Train_OP',
        dataset_file_path='data/Train_Outpatientdata-1542865627584.csv'
    )

    train = project.addDataset(
        dataset_name='Train_1542865627584',
        dataset_description='Train_Tgt',
        dataset_file_path='data/Train-1542865627584.csv'
    )


Transform your raw data
-----------------------

Create recipe and template for feature engineering
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

this recipe use all 4 data and add some features in combined one data format 
w.r.t important features which we elplored from EDA and understanding.

Few features examples can see below-

Adding New Feature :: Claim_Duration
Adding New Feature :: Bene_Age
Adding New Feature ::Total Number of false claims filed by a Provider
Adding New Feature :: Total Number of claims or cases seen by Attending Physician
Adding New Feature :: Total Number of claims or cases seen by Other Physician
Adding New Feature :: Total Unique Number of Diagnosis Group Codes used by a PROVIDER
Adding New Feature :: Sum of patients age treated by a Provider
Adding New Feature :: Sum of Insc Claim Re-Imb Amount for a Provider
Adding New Feature :: Total number of RKD Patients seen by a Provider
Adding New Feature :: Claim_Duration

Note- You can see the Feature engineering code from transform folder in Feature_Enginerring.ipynb file.


.. code:: ipython3

    feature_engineering_template = TemplateV2(
        name="feature_engineering", description="1st feature_engineering of HealtCare faud data", project_id=project.id,
        source="CUSTOM", status="ACTIVE", tags=["UI", "Scalar"]
    )
    feature_engineering_transform = TemplateTransformV2(
        type = "python", params=dict(notebookName="Feature_Enginerring.ipynb"))

    feature_engineering_template.base_transforms = [feature_engineering_transform]
    feature_engineering_template.publish("transforms/Feature_Enginerring.ipynb")

    feature_engineering_transform = Transform()
    feature_engineering_transform.templateId = feature_engineering_template.id
    feature_engineering_transform.name='features'
    feature_engineering_transform.variables = {
        'inputDataset': 'Train_Beneficiarydata-1542865627584',
        'inputDataset2': 'Train_Inpatientdata-1542865627584',
        'inputDataset3': 'Train_Outpatientdata-1542865627584',
        'inputDataset4': 'Train_1542865627584',
        'outputDataset': 'train_iobp_df'
    }
    feature_engineering.add_transform(feature_engineering_transform)
    feature_engineering.run()



Output dataset and review sample
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: ipython3

    train_iobp_df=feature_engineering.getChildrenDatasets()['train_iobp_df']
    train_iobp_dft.getData(5)




Create recipe and template to Aggregate raw data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

this recipe use output of Feature engineered data add some extra features with data aggregation which also help us to make EDA and visualisation.

Few Data aggregation examples can see below-

   -  Claim Duration for Potentially Fraud & Non-Fraud Providers.
   -  Distribution of Fraud & Non-fraud claims.
   -  Claim Duration of both the genders for Potentially Fraud & Non-Fraud Providers.
   -  Claim Duration patient life status for Potentially Fraud & Non-Fraud Providers.
   -  Claim Re-Imb Amount for Potentially Fraud & Non-Fraud Providers.
   -  Annual IP Re-Imb Amount for Potentially Fraud & Non-Fraud Providers.
   -  Claim Re-Imb Amount of all human races for Potentially Fraud & Non-Fraud Providers.


	

Note- You can see the data aggregation code from transform folder in Adding_Aggregated_Features.ipynb file.


.. code:: ipython3

    data_aggregation_template = TemplateV2(
        name="Data_aggregation", description="Aggregation of HealtCare fraud data", project_id=project.id,
        source="CUSTOM", status="ACTIVE", tags=["UI", "Scalar"]
    )
    data_aggregation_transform = TemplateTransformV2(
        type = "python", params=dict(notebookName="Adding_Aggregated_Features.ipynb"))

    data_aggregation_template.base_transforms = [data_aggregation_transform]
    data_aggregation_template.publish("transforms/Adding_Aggregated_Features.ipynb")
    data_aggregation_transform = Transform()
    data_aggregation_transform.templateId = data_aggregation_template.id
    data_aggregation_transform.name='Healthcare data aggregation'
    data_aggregation_transform.variables = {
        'inputDataset5': 'train_iobp_df',

        'outputDataset2': 'train_iobp_df_final'
    }
    data_aggregation.add_transform(data_aggregation_transform)
    data_aggregation.run()



Output dataset and review sample
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code:: ipython3

    train_iobp_df_final=data_aggregation.getChildrenDatasets()['train_iobp_df_final']
    train_iobp_df_final.getData(5)



Build ML model
--------------

Add the dataset
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

As part of the model building step, we first feature engineered by combining all 4 datasets with new
features as we can see above examples.we uploaded at the start of the
build pipeline.

.. code:: ipython3

    train_iobp_df_final=data_aggregation.getChildrenDatasets()['train_iobp_df_final']
    classifier_recipe=project.addRecipe([train_iobp_df_final], name='ML Classification')

Create a recipe to build a random forest, ada boost and lighgbm model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In this step we build the ML models. Please note that once the models
built, it is automatically stored in RapidCanvas repository and can be
retrieved for prediction in the later steps.

We use Sklearn, and Pycaret for Random forest and Adaboost, Lightgbm model respectively.

Note that this marks the end of the build pipeline

.. code:: ipython3


    classifier_recipe_template = TemplateV2(
        name="ML Classification", description="Machine learning classification of HealtCare Fraud ", project_id=project.id,
        source="CUSTOM", status="ACTIVE", tags=["UI", "Scalar"]
    )
    classifier_recipe_transform = TemplateTransformV2(
        type = "python", params=dict(notebookName="ML_Classifier.ipynb"))

    classifier_recipe_template.base_transforms = [classifier_recipe_transform]
    classifier_recipe_template.publish("transforms/ML_Classifier.ipynb")

.. code:: ipython3

    classifier_recipe_transform = Transform()
    classifier_recipe_transform.templateId = classifier_recipe_template.id
    classifier_recipe_transform.name='Healthcare Fraud Classification'
    classifier_recipe_transform.variables = {
        'inputDataset6': 'train_iobp_df_final',

        'outputDataset3': 'RFC_Score',
        'outputDataset4': 'ADA_Score',
        'outputDataset5': 'LGM_Score'
    }
    classifier_recipe.add_transform(classifier_recipe_transform)

.. code:: ipython3

    classifier_recipe_recipe.run()

Output dataset and review sample
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We can take a look at Lightgbm classification model output.

.. code:: ipython3

    classifier_recipe.getChildrenDatasets()['LGM_Score'].getData()


We can take a look at RandomForest classification model output.
.. code:: ipython3

    classifier_recipe.getChildrenDatasets()['RFC_Score'].getData()

We can take a look at AdaBoost classification model output.

.. code:: ipython3

    classifier_recipe.getChildrenDatasets()['ADA_Score'].getData()





















Exploratory Data Analysis
--------------------------------------------

To understand data,it is very important ot explore data with the help of mathemetical operation and plotiing the relationships.
So, we have done some EDA on Beneficiary and entire dataset combined and can take look below.

Beneficiary Data EDA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We can explore EDA implementation on Beneficiary data with code below. 

Create a recipe and template to build Beneficiary Data EDA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: ipython3

    EDA_Beneficiary_Data_recipe=project.addRecipe([Beneficiarydata], name='EDA_Beneficiary')

.. code:: ipython3

    EDA_Beneficiary_Data__template = TemplateV2(
        name="EDA_Beneficiary", description="EDA_Beneficiary_Data", project_id=project.id,
        source="CUSTOM", status="ACTIVE", tags=["UI", "Visualization"]
    )
    EDA_Beneficiary_Data__template_transform = TemplateTransformV2(
        type = "python", params=dict(notebookName="EDA_Beneficiary_Data.ipynb"))

    EDA_Beneficiary_Data__template.base_transforms = [EDA_Beneficiary_Data__template_transform]
    EDA_Beneficiary_Data__template.publish("transforms/EDA_Beneficiary_Data.ipynb")

.. code:: ipython3

    EDA_Beneficiary_Data_template_transform = Transform()
    EDA_Beneficiary_Data_template_transform.templateId = EDA_Beneficiary_Data__template.id
    EDA_Beneficiary_Data_template_transform.name='EDA_Beneficiary_Chart'
    EDA_Beneficiary_Data_template_transform.variables = {
        'inputBeneDataset2': 'Train_Beneficiarydata-1542865627584',

        'EDA_Beneficiary_Data': 'EDA_Beneficiary_Data'
    }

    EDA_Beneficiary_Data_recipe.add_transform(EDA_Beneficiary_Data_template_transform)

.. code:: ipython3

    EDA_Beneficiary_Data_recipe.run()

Output charts
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Once run EDA_Beneficiary_Data recipe you can have look the all chart you plotted on Rapidcanvas UI <https://staging.dev.rapidcanvas.net/>`__



Entire Data EDA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We can explore EDA implementation on entire dataset combined and can explore implementation below. 

Create a recipe and template to build Entire Data EDA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: ipython3

    EDA_Inpatient_Outpatient_Data_recipe=project.addRecipe([Inpatientdata,Outpatientdata,train,Beneficiarydata], name='EDA_Inpatient_Outpatient_Data')


.. code:: ipython3

    EDA_Inpatient_Outpatient_Data_template = TemplateV2(
        name="EDA_Inpatient_Outpatient_Data", description="EDA_Inpatient_Outpatient_Data", project_id=project.id,
        source="CUSTOM", status="ACTIVE", tags=["UI", "Visualization"]
    )
    EDA_Inpatient_Outpatient_Data_template_transform = TemplateTransformV2(
        type = "python", params=dict(notebookName="EDA_Inpatient_Outpatient_Data.ipynb"))

    EDA_Inpatient_Outpatient_Data_template.base_transforms = [EDA_Inpatient_Outpatient_Data_template_transform]
    EDA_Inpatient_Outpatient_Data_template.publish("transforms/EDA_Inpatient_Outpatient_Data.ipynb")


.. code:: ipython3

    EDA_Inpatient_Outpatient_Data_template_transform = Transform()
    EDA_Inpatient_Outpatient_Data_template_transform.templateId = EDA_Inpatient_Outpatient_Data_template.id
    EDA_Inpatient_Outpatient_Data_template_transform.name='EDA_Inpatient_Outpatient_Chart'
    EDA_Inpatient_Outpatient_Data_template_transform.variables = {
        'inputBeneDataset3': 'Train_Inpatientdata-1542865627584',
        'inputBeneDataset4': 'Train_Outpatientdata-1542865627584',
        'inputBeneDataset6': 'Train_Beneficiarydata-1542865627584',
        'inputBeneDataset5': 'Train_1542865627584',


        'EDA_Inpatient_Outpatient_Data': 'EDA_Inpatient_Outpatient_Data'}


    EDA_Inpatient_Outpatient_Data_recipe.add_transform(EDA_Inpatient_Outpatient_Data_template_transform)

.. code:: ipython3

    EDA_Inpatient_Outpatient_Data_recipe.run()

Output charts
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Once run EDA_Inpatient_Outpatient_Data recipe you can have look the all chart you plotted on Rapidcanvas UI <https://staging.dev.rapidcanvas.net/>`__